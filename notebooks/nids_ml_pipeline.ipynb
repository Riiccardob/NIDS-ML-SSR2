{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.10.0","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NIDS-ML: Network Intrusion Detection System\n\nPipeline completa: preprocessing, feature engineering, training, evaluation e test su PCAP.\n\n**Requisiti Kaggle**:\n- Dataset CIC-IDS2017 (CSV)\n- Dataset `cicids2017-test-pcap` (opzionale, per test PCAP)","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup Ambiente","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nfrom pathlib import Path\n\nif Path(\"/kaggle/input\").exists():\n    ENV = \"kaggle\"\n    PROJECT_ROOT = Path(\"/kaggle/working\")\n    DATA_INPUT = Path(\"/kaggle/input\")\nelif Path(\"/content\").exists():\n    ENV = \"colab\"\n    PROJECT_ROOT = Path(\"/content/NIDS-ML\")\n    DATA_INPUT = Path(\"/content\")\nelse:\n    ENV = \"local\"\n    PROJECT_ROOT = Path.cwd()\n    if not (PROJECT_ROOT / \"src\").exists():\n        PROJECT_ROOT = PROJECT_ROOT.parent\n    DATA_INPUT = PROJECT_ROOT / \"data\" / \"raw\"\n\nprint(f\"Ambiente: {ENV}\")\nprint(f\"Project root: {PROJECT_ROOT}\")\nprint(f\"Data input: {DATA_INPUT}\")\n\nsys.path.insert(0, str(PROJECT_ROOT))\nos.chdir(PROJECT_ROOT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"REPO_URL = \"https://github.com/Riiccardob/NIDS-ML-SSR2\"\n\nif ENV in [\"kaggle\", \"colab\"]:\n    if not (PROJECT_ROOT / \"src\").exists():\n        print(f\"Cloning project from {REPO_URL}...\")\n        !git clone {REPO_URL} temp_repo\n        !cp -r temp_repo/* {PROJECT_ROOT}/\n        !rm -rf temp_repo\n        print(\"Project cloned.\")\n        if (PROJECT_ROOT / \"requirements.txt\").exists():\n            !pip install -q -r {PROJECT_ROOT}/requirements.txt\n    else:\n        print(\"Project already loaded.\")\n\nif (PROJECT_ROOT / \"src\").exists():\n    print(f\"\\nModuli disponibili:\")\n    for f in sorted((PROJECT_ROOT / \"src\").glob(\"*.py\")):\n        print(f\"  - {f.name}\")\nelse:\n    raise FileNotFoundError(\"Cartella src/ non trovata!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for d in [\"data/raw\", \"data/processed\", \"artifacts\", \"models\", \"logs\", \"reports\"]:\n    (PROJECT_ROOT / d).mkdir(parents=True, exist_ok=True)\nprint(\"Directory create.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if ENV in [\"kaggle\", \"colab\"]:\n    dataset_patterns = [\"cicids2017\", \"cic-ids-2017\", \"cicids\", \"ids2017\", \"network-intrusion-dataset\"]\n    dataset_path = None\n    for p in DATA_INPUT.iterdir():\n        name_lower = p.name.lower()\n        if \"pcap\" in name_lower:\n            continue\n        if any(pat in name_lower for pat in dataset_patterns):\n            if list(p.glob(\"**/*.csv\")):\n                dataset_path = p\n                break\n    if dataset_path:\n        print(f\"Dataset CSV trovato: {dataset_path}\")\n        raw_dir = PROJECT_ROOT / \"data\" / \"raw\"\n        for csv in dataset_path.glob(\"**/*.csv\"):\n            dest = raw_dir / csv.name\n            if not dest.exists():\n                !cp \"{csv}\" \"{dest}\"\n        print(f\"CSV copiati in: {raw_dir}\")\n    else:\n        print(\"ERRORE: Dataset CIC-IDS2017 non trovato!\")\n\ncsv_files = list((PROJECT_ROOT / \"data\" / \"raw\").glob(\"*.csv\"))\nprint(f\"\\nCSV disponibili: {len(csv_files)}\")\nfor f in csv_files:\n    size_mb = f.stat().st_size / (1024**2)\n    print(f\"  - {f.name}: {size_mb:.1f} MB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Preprocessing","metadata":{}},{"cell_type":"code","source":"from src.preprocessing import main as preprocessing_main\nfrom src.preprocessing import load_processed_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nimport sys\nsys.argv = ['preprocessing.py', '--balance-ratio', '2.0', '--n-jobs', '4']\npreprocessing_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train, val, test, mappings = load_processed_data()\nprint(f\"Train: {len(train):,} | Val: {len(val):,} | Test: {len(test):,}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Feature Engineering","metadata":{}},{"cell_type":"code","source":"from src.feature_engineering import main as feature_engineering_main\nfrom src.feature_engineering import load_artifacts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['feature_engineering.py', '--n-features', '30', '--rf-estimators', '100', '--n-jobs', '4']\nfeature_engineering_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler, selected_features, importances, scaler_columns = load_artifacts()\nprint(f\"Feature selezionate: {len(selected_features)}\")\nprint(f\"Colonne scaler: {len(scaler_columns)}\")\nprint(f\"\\nTop 10 feature:\")\nfor i, feat in enumerate(selected_features[:10]):\n    print(f\"  {i+1:2}. {feat}: {importances[feat]:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Training Modelli (Definitivo)\n\nParametri: `--n-iter 50 --cv 5` (250 fit per modello)","metadata":{}},{"cell_type":"code","source":"from src.training.random_forest import main as rf_main\nfrom src.training.xgboost_model import main as xgb_main\nfrom src.training.lightgbm_model import main as lgbm_main","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# Random Forest\nsys.argv = ['random_forest.py', '--task', 'binary', '--n-iter', '50', '--cv', '5', '--n-jobs', '4']\nrf_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# XGBoost\nsys.argv = ['xgboost_model.py', '--task', 'binary', '--n-iter', '50', '--cv', '5', '--n-jobs', '4']\nxgb_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# LightGBM\nsys.argv = ['lightgbm_model.py', '--task', 'binary', '--n-iter', '50', '--cv', '5', '--n-jobs', '4']\nlgbm_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nprint(\"Modelli addestrati:\")\nfor model_dir in (PROJECT_ROOT / \"models\").iterdir():\n    if model_dir.is_dir() and model_dir.name != \"best_model\":\n        results_file = model_dir / \"results_binary.json\"\n        if results_file.exists():\n            with open(results_file) as f:\n                results = json.load(f)\n            metrics = results.get('validation_metrics', {})\n            print(f\"\\n  {model_dir.name}: Acc={metrics.get('accuracy', 0):.4f}, F1={metrics.get('f1', 0):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Evaluation","metadata":{}},{"cell_type":"code","source":"from src.evaluation import main as evaluation_main","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['evaluation.py', '--model-path', 'models/random_forest/model_binary.pkl']\nevaluation_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['evaluation.py', '--model-path', 'models/xgboost/model_binary.pkl']\nevaluation_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['evaluation.py', '--model-path', 'models/lightgbm/model_binary.pkl']\nevaluation_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Confronto e Selezione Best Model","metadata":{}},{"cell_type":"code","source":"from src.compare_models import main as compare_main","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['compare_models.py', '--max-fpr', '0.02', '--max-latency-ms', '1.0']\ncompare_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_dir = PROJECT_ROOT / \"models\" / \"best_model\"\nif best_model_dir.exists():\n    print(f\"Best model: {best_model_dir}\")\n    for f in best_model_dir.iterdir():\n        print(f\"  - {f.name}\")\n    metadata_file = best_model_dir / \"metadata.json\"\n    if metadata_file.exists():\n        with open(metadata_file) as f:\n            print(f\"\\nBest: {json.load(f).get('best_model', 'N/A')}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Visualizzazioni","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom IPython.display import Image, display\n\nscorecard_img = PROJECT_ROOT / \"models\" / \"best_model\" / \"scorecard_comparison.png\"\nif scorecard_img.exists():\n    print(\"Scorecard:\")\n    display(Image(filename=str(scorecard_img)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_name = \"lightgbm\"\nmetadata_file = PROJECT_ROOT / \"models\" / \"best_model\" / \"metadata.json\"\nif metadata_file.exists():\n    with open(metadata_file) as f:\n        best_model_name = json.load(f).get('best_model', 'lightgbm')\n\nreport_dir = PROJECT_ROOT / \"reports\" / best_model_name\nif report_dir.exists():\n    for img_name in [\"confusion_matrix_binary.png\", \"roc_curve_binary.png\"]:\n        img_path = report_dir / img_name\n        if img_path.exists():\n            print(f\"\\n{img_name}:\")\n            display(Image(filename=str(img_path)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## 8. Test Sniffer su PCAP\n\nDataset: `cicids2017-test-pcap` con `test_pcap/*.pcap`","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport joblib\nfrom collections import defaultdict\nfrom tqdm.notebook import tqdm\n\npcap_patterns = [\"pcap\", \"test-pcap\", \"test_pcap\"]\npcap_dataset_path = None\npcap_files = []\n\nif ENV in [\"kaggle\", \"colab\"]:\n    for p in DATA_INPUT.iterdir():\n        if any(pat in p.name.lower() for pat in pcap_patterns):\n            found = list(p.glob(\"**/*.pcap\")) + list(p.glob(\"**/*.pcapng\"))\n            if found:\n                pcap_dataset_path = p\n                pcap_files = found\n                break\n\nif pcap_files:\n    print(f\"Dataset PCAP: {pcap_dataset_path}\")\n    for f in pcap_files:\n        print(f\"  - {f.name}: {f.stat().st_size/(1024**2):.1f} MB\")\nelse:\n    print(\"Dataset PCAP non trovato (opzionale).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if pcap_files:\n    print(\"Caricamento modello...\")\n    model = joblib.load(PROJECT_ROOT / \"models\" / \"best_model\" / \"model_binary.pkl\")\n    scaler, selected_features, _, scaler_columns = load_artifacts()\n    model_feat_path = PROJECT_ROOT / \"models\" / \"best_model\" / \"features_binary.json\"\n    if model_feat_path.exists():\n        with open(model_feat_path) as f:\n            selected_features = json.load(f)\n    print(f\"  Features: {len(selected_features)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LightweightFlow:\n    def __init__(self, src_ip, dst_ip, src_port, dst_port, protocol):\n        self.src_ip, self.dst_ip = src_ip, dst_ip\n        self.src_port, self.dst_port = src_port, dst_port\n        self.protocol = protocol\n        self.fwd_lengths, self.bwd_lengths = [], []\n        self.fwd_times, self.bwd_times = [], []\n        self.tcp_flags = defaultdict(int)\n        self.start_time = self.end_time = None\n    \n    @property\n    def flow_id(self): return f\"{self.src_ip}:{self.src_port}->{self.dst_ip}:{self.dst_port}\"\n    @property\n    def total_packets(self): return len(self.fwd_lengths) + len(self.bwd_lengths)\n    \n    def add_packet(self, pkt_len, ts, is_fwd, flags=None):\n        (self.fwd_lengths if is_fwd else self.bwd_lengths).append(pkt_len)\n        (self.fwd_times if is_fwd else self.bwd_times).append(ts)\n        if self.start_time is None: self.start_time = ts\n        self.end_time = ts\n        if flags:\n            for f in 'FSRPAU':\n                if f in flags: self.tcp_flags[f] += 1\n    \n    def extract_features(self):\n        feat = {}\n        dur = (self.end_time - self.start_time) if self.start_time else 0\n        feat['Flow Duration'] = dur * 1e6\n        feat['Total Fwd Packets'] = feat['Subflow Fwd Packets'] = len(self.fwd_lengths)\n        feat['Total Backward Packets'] = feat['Subflow Bwd Packets'] = len(self.bwd_lengths)\n        fwd = self.fwd_lengths or [0]\n        bwd = self.bwd_lengths or [0]\n        feat['Total Length of Fwd Packets'] = feat['Subflow Fwd Bytes'] = sum(fwd)\n        feat['Total Length of Bwd Packets'] = feat['Subflow Bwd Bytes'] = sum(bwd)\n        feat['Fwd Packet Length Max'], feat['Fwd Packet Length Min'] = max(fwd), min(fwd)\n        feat['Fwd Packet Length Mean'] = feat['Avg Fwd Segment Size'] = np.mean(fwd)\n        feat['Fwd Packet Length Std'] = np.std(fwd, ddof=0) if len(fwd)>1 else 0\n        feat['Bwd Packet Length Max'], feat['Bwd Packet Length Min'] = max(bwd), min(bwd)\n        feat['Bwd Packet Length Mean'] = feat['Avg Bwd Segment Size'] = np.mean(bwd)\n        feat['Bwd Packet Length Std'] = np.std(bwd, ddof=0) if len(bwd)>1 else 0\n        all_len = fwd + bwd\n        feat['Packet Length Mean'] = feat['Average Packet Size'] = np.mean(all_len)\n        feat['Packet Length Std'] = np.std(all_len, ddof=0) if len(all_len)>1 else 0\n        feat['Packet Length Variance'] = np.var(all_len, ddof=0) if len(all_len)>1 else 0\n        feat['Max Packet Length'] = max(all_len)\n        if dur > 0:\n            feat['Flow Bytes/s'] = sum(all_len)/dur\n            feat['Flow Packets/s'] = self.total_packets/dur\n            feat['Fwd Packets/s'] = len(self.fwd_lengths)/dur\n            feat['Bwd Packets/s'] = len(self.bwd_lengths)/dur\n        else:\n            feat['Flow Bytes/s']=feat['Flow Packets/s']=feat['Fwd Packets/s']=feat['Bwd Packets/s']=0\n        def iat(t): return [t[i+1]-t[i] for i in range(len(t)-1)] if len(t)>1 else [0]\n        all_t = sorted(self.fwd_times + self.bwd_times)\n        for prefix, times in [('Flow IAT', iat(all_t)), ('Fwd IAT', iat(sorted(self.fwd_times))), ('Bwd IAT', iat(sorted(self.bwd_times)))]:\n            feat[f'{prefix} Mean'] = np.mean(times)*1e6 if times else 0\n            feat[f'{prefix} Std'] = np.std(times,ddof=0)*1e6 if len(times)>1 else 0\n            feat[f'{prefix} Max'] = max(times)*1e6 if times else 0\n            feat[f'{prefix} Min'] = min(times)*1e6 if times else 0\n            if 'Fwd' in prefix or 'Bwd' in prefix: feat[f'{prefix} Total'] = sum(times)*1e6\n        for f,n in [('F','FIN'),('S','SYN'),('R','RST'),('P','PSH'),('A','ACK'),('U','URG')]:\n            feat[f'{n} Flag Count'] = self.tcp_flags.get(f,0)\n        feat['Fwd Header Length'] = feat['Fwd Header Length.1'] = len(self.fwd_lengths)*20\n        feat['Bwd Header Length'] = len(self.bwd_lengths)*20\n        feat['Init_Win_bytes_forward'] = feat['Init_Win_bytes_backward'] = 65535\n        for s in ['Mean','Std','Max','Min']: feat[f'Active {s}']=feat[f'Idle {s}']=0\n        return feat","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_flow(flow, model, scaler, scaler_cols, sel_feat):\n    ext = flow.extract_features()\n    df = pd.DataFrame([{c: ext.get(c,0) for c in scaler_cols}])\n    df_sc = pd.DataFrame(scaler.transform(df), columns=scaler_cols)\n    pred = int(model.predict(df_sc[sel_feat])[0])\n    prob = float(model.predict_proba(df_sc[sel_feat])[0][1]) if hasattr(model,'predict_proba') else 0.5\n    return pred, prob\n\ndef analyze_pcap(pcap_path, model, scaler, scaler_cols, sel_feat, timeout=60, min_pkt=2, interval=100000):\n    from scapy.all import PcapReader, IP, TCP, UDP\n    flows = {}\n    res = {'pcap': pcap_path.name, 'packets_processed': 0, 'flows_analyzed': 0, 'attacks_detected': 0, 'benign_detected': 0, 'attack_flows': []}\n    print(f\"\\n{'='*60}\\nAnalisi: {pcap_path.name}\\n{'='*60}\")\n    try:\n        with PcapReader(str(pcap_path)) as reader:\n            for pkt in reader:\n                if not pkt.haslayer(IP): continue\n                ip = pkt[IP]\n                src_ip, dst_ip, proto, pkt_len, ts = ip.src, ip.dst, ip.proto, len(pkt), float(pkt.time)\n                src_port = dst_port = 0\n                flags = None\n                if pkt.haslayer(TCP): src_port, dst_port, flags = pkt[TCP].sport, pkt[TCP].dport, str(pkt[TCP].flags)\n                elif pkt.haslayer(UDP): src_port, dst_port = pkt[UDP].sport, pkt[UDP].dport\n                if (src_ip, src_port) < (dst_ip, dst_port):\n                    key, is_fwd = (src_ip, dst_ip, src_port, dst_port, proto), True\n                else:\n                    key, is_fwd = (dst_ip, src_ip, dst_port, src_port, proto), False\n                if key not in flows: flows[key] = LightweightFlow(*key)\n                flows[key].add_packet(pkt_len, ts, is_fwd, flags)\n                res['packets_processed'] += 1\n                if res['packets_processed'] % interval == 0:\n                    print(f\"  Pkts: {res['packets_processed']:,} | Flows: {len(flows):,} | Attacks: {res['attacks_detected']}\")\n                    expired = [k for k,f in flows.items() if f.end_time and (ts-f.end_time)>timeout]\n                    for k in expired:\n                        f = flows.pop(k)\n                        if f.total_packets >= min_pkt:\n                            p, pr = predict_flow(f, model, scaler, scaler_cols, sel_feat)\n                            res['flows_analyzed'] += 1\n                            if p == 1:\n                                res['attacks_detected'] += 1\n                                if len(res['attack_flows'])<100: res['attack_flows'].append({'flow_id':f.flow_id,'prob':pr,'pkts':f.total_packets})\n                            else: res['benign_detected'] += 1\n        print(f\"  Final flows: {len(flows):,}\")\n        for f in tqdm(flows.values(), desc=\"Analyzing\"):\n            if f.total_packets >= min_pkt:\n                p, pr = predict_flow(f, model, scaler, scaler_cols, sel_feat)\n                res['flows_analyzed'] += 1\n                if p == 1:\n                    res['attacks_detected'] += 1\n                    if len(res['attack_flows'])<100: res['attack_flows'].append({'flow_id':f.flow_id,'prob':pr,'pkts':f.total_packets})\n                else: res['benign_detected'] += 1\n    except Exception as e:\n        print(f\"  ERROR: {e}\")\n        res['error'] = str(e)\n    return res","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nall_pcap_results = []\nif pcap_files:\n    for pcap_path in pcap_files:\n        r = analyze_pcap(pcap_path, model, scaler, scaler_columns, selected_features)\n        all_pcap_results.append(r)\n        print(f\"\\n  {r['pcap']}: Pkts={r['packets_processed']:,} Flows={r['flows_analyzed']:,} Attacks={r['attacks_detected']:,}\")\nelse:\n    print(\"Nessun PCAP.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if all_pcap_results:\n    print(\"\\n\" + \"=\"*70 + \"\\nRIEPILOGO PCAP\\n\" + \"=\"*70)\n    tot_pkt = sum(r['packets_processed'] for r in all_pcap_results)\n    tot_fl = sum(r['flows_analyzed'] for r in all_pcap_results)\n    tot_att = sum(r['attacks_detected'] for r in all_pcap_results)\n    print(f\"\\nTotale: Pkts={tot_pkt:,} Flows={tot_fl:,} Attacks={tot_att:,} ({tot_att/tot_fl*100:.1f}%)\" if tot_fl>0 else \"\")\n    print(f\"\\n{'PCAP':<35} {'Packets':>12} {'Flows':>10} {'Attacks':>10} {'%':>8}\")\n    print(\"-\"*77)\n    for r in all_pcap_results:\n        pct = r['attacks_detected']/r['flows_analyzed']*100 if r['flows_analyzed']>0 else 0\n        print(f\"{r['pcap']:<35} {r['packets_processed']:>12,} {r['flows_analyzed']:>10,} {r['attacks_detected']:>10,} {pct:>7.1f}%\")\n    with open(PROJECT_ROOT/\"reports\"/\"pcap_results.json\",'w') as f: json.dump(all_pcap_results,f,indent=2,default=str)\n    print(f\"\\nSalvato: reports/pcap_results.json\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Download Output","metadata":{}},{"cell_type":"code","source":"if ENV in [\"kaggle\", \"colab\"]:\n    import zipfile\n    zip_path = PROJECT_ROOT / \"nids_ml_output.zip\"\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n        for f in (PROJECT_ROOT/\"artifacts\").glob(\"*\"): z.write(f, f\"artifacts/{f.name}\")\n        for d in (PROJECT_ROOT/\"models\").iterdir():\n            if d.is_dir():\n                for f in d.glob(\"*\"): z.write(f, f\"models/{d.name}/{f.name}\")\n        for f in (PROJECT_ROOT/\"reports\").rglob(\"*\"):\n            if f.is_file(): z.write(f, f\"reports/{f.relative_to(PROJECT_ROOT/'reports')}\")\n    print(f\"ZIP: {zip_path} ({zip_path.stat().st_size/(1024**2):.1f} MB)\")\nelse:\n    print(\"Locale - output in cartella progetto.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10. Riepilogo","metadata":{}},{"cell_type":"code","source":"print(\"=\"*70 + \"\\nPIPELINE COMPLETATA\\n\" + \"=\"*70)\nbest_report = PROJECT_ROOT/\"models\"/\"best_model\"/\"comparison_results.json\"\nif best_report.exists():\n    with open(best_report) as f: results = json.load(f)\n    best = max(results, key=lambda x: x.get('score',0))\n    print(f\"\\nBest Model: {best['model_name'].upper()}\")\n    for k,v in best.get('metrics',{}).items():\n        if isinstance(v,float): print(f\"  {k}: {v:.4f}\")\nif all_pcap_results:\n    print(f\"\\nPCAP Test: {sum(r['flows_analyzed'] for r in all_pcap_results):,} flows, {sum(r['attacks_detected'] for r in all_pcap_results):,} attacks\")\nprint(\"\\n\" + \"=\"*70 + \"\\nComandi locali:\\n  sudo python src/sniffer.py --interface eth0\\n  sudo python src/sniffer.py --pcap file.pcap\\n\" + \"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
