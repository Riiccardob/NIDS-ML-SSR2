{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6376134,"sourceType":"datasetVersion","datasetId":3674161}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8c597463-b73d-4dff-8be9-77f0357237b5","cell_type":"markdown","source":"# üõ°Ô∏è NIDS-ML Pipeline - Kaggle (Strict & Optimized)\n\nVersione finale dell'architettura per il training su Kaggle.\n\n### Caratteristiche:\n- **Clean Run:** Configurabile per pulire o mantenere i risultati precedenti.\n- **Dataset Copy:** Importazione stabile dei dati (no symlink).\n- **Strict Mode:** Chiamate agli script senza parametri superflui.\n- **Repo Management:** Download e setup pulito della sola cartella `src/`.","metadata":{}},{"id":"337e229e-4003-46c9-a8ab-8f803e77a428","cell_type":"code","source":"# ==========================================\n# 1. CONFIGURAZIONE (STRICT)\n# ==========================================\n\n# --- 1.1 Configurazione Pipeline ---\nCLEAN_RUN = True      # Se True: Cancella data/processed, artifacts e tuning_results prima di iniziare\n\n# --- 1.2 Configurazione Tuning ---\nMODEL_TYPE = \"lightgbm\"    # Opzioni: random_forest,xgboost,lightgbm\nN_TRIALS = 60    # Numero di trial per Optuna\nTIMEOUT = 60       # Timeout in secondi (es. 3600 = 1 ora)\n\n# --- 1.3 Configurazione Ambiente ---\nREPO_URL = \"https://github.com/riiccardob/nids-ml-ssr2\"\nBRANCH = \"main\"\nKAGGLE_INPUT_PATH = \"/kaggle/input/network-intrusion-dataset/\" # Path del dataset su Kaggle\n\n# ==========================================\n# VALIDAZIONE PARAMETRI\n# ==========================================\nALLOWED_MODELS = {\"random_forest\", \"xgboost\", \"lightgbm\"}\nif MODEL_TYPE not in ALLOWED_MODELS:\n    raise ValueError(f\"‚ùå Modello '{MODEL_TYPE}' non valido. Scegli tra: {ALLOWED_MODELS}\")\n\nif N_TRIALS is None and TIMEOUT is None:\n    raise ValueError(\"‚ùå Devi specificare almeno uno tra N_TRIALS o TIMEOUT.\")\n\nprint(f\"‚úÖ Configurazione valida: Modello={MODEL_TYPE}, CleanRun={CLEAN_RUN}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:42:12.231624Z","iopub.execute_input":"2026-01-25T19:42:12.232119Z","iopub.status.idle":"2026-01-25T19:42:12.269548Z","shell.execute_reply.started":"2026-01-25T19:42:12.232071Z","shell.execute_reply":"2026-01-25T19:42:12.266271Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Configurazione valida: Modello=lightgbm, CleanRun=True\n","output_type":"stream"}],"execution_count":1},{"id":"5478b746-4e45-4564-95c1-922dedfc8e42","cell_type":"code","source":"# ==========================================\n# 2. SETUP AMBIENTE (Repo & Requirements)\n# ==========================================\nimport os\nimport shutil\nimport sys\n\n# Rileva ambiente Kaggle\nKAGGLE_ENV = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '') != ''\n\nif KAGGLE_ENV:\n    print(\"üöÄ Ambiente Kaggle rilevato. Setup repo...\")\n    \n    repo_folder = f\"NIDS-ML-SSR2-{BRANCH}\"\n    zip_name = \"repo.zip\"\n    \n    # Scarica solo se src non esiste o se vogliamo forzare un aggiornamento pulendo manualmente\n    # Nota: Qui src viene mantenuto tra le run se non esplicitamente cancellato, \n    # ma per sicurezza riscarichiamo se manca.\n    if not os.path.exists(\"src\"):\n        print(f\"üì• Download repo da {REPO_URL}...\")\n        os.system(f\"wget -q {REPO_URL}/archive/refs/heads/{BRANCH}.zip -O {zip_name}\")\n        os.system(f\"unzip -qo {zip_name}\")\n        \n        # Setup cartelle\n        if os.path.exists(f\"{repo_folder}/src\"):\n            shutil.move(f\"{repo_folder}/src\", \"./src\")\n        if os.path.exists(f\"{repo_folder}/requirements.txt\"):\n            shutil.move(f\"{repo_folder}/requirements.txt\", \"./requirements.txt\")\n            \n        # Cleanup download\n        if os.path.exists(repo_folder): shutil.rmtree(repo_folder)\n        if os.path.exists(zip_name): os.remove(zip_name)\n    \n    # Installazione dipendenze\n    if os.path.exists(\"requirements.txt\"):\n        print(\"üîß Installazione dipendenze...\")\n        os.system(\"pip install -q -r requirements.txt\")\n        # Fix specifico per Kaggle (conflitto dill/datasets)\n        os.system(\"pip install -q --upgrade datasets\")\n        \n    sys.path.append(os.path.abspath(\"src\"))\n    print(\"‚úÖ Setup ambiente completato.\")\nelse:\n    print(\"üíª Ambiente Locale. Uso i file esistenti.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:42:12.275127Z","iopub.execute_input":"2026-01-25T19:42:12.275578Z","iopub.status.idle":"2026-01-25T19:42:42.352472Z","shell.execute_reply.started":"2026-01-25T19:42:12.275519Z","shell.execute_reply":"2026-01-25T19:42:42.351313Z"}},"outputs":[{"name":"stdout","text":"üöÄ Ambiente Kaggle rilevato. Setup repo...\nüì• Download repo da https://github.com/riiccardob/nids-ml-ssr2...\nüîß Installazione dipendenze...\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2.6/2.6 MB 22.2 MB/s eta 0:00:00\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 120.0/120.0 kB 5.2 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.4.2 requires dill<0.4.1,>=0.3.0, but you have dill 0.4.1 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 515.2/515.2 kB 8.0 MB/s eta 0:00:00\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 119.7/119.7 kB 5.3 MB/s eta 0:00:00\n‚úÖ Setup ambiente completato.\n","output_type":"stream"}],"execution_count":2},{"id":"67c2aa59-6df5-4acc-8e71-12442915eaaf","cell_type":"code","source":"# ==========================================\n# 3. CLEAN RUN MANAGER\n# ==========================================\n# Gestisce la pulizia delle cartelle di output in base a CLEAN_RUN\n\nDIRS_TO_CLEAN = [\"data/processed\", \"artifacts\", \"tuning_results\"]\n\nif CLEAN_RUN:\n    print(\"üßπ CLEAN_RUN = True: Pulizia cartelle di output...\")\n    for directory in DIRS_TO_CLEAN:\n        if os.path.exists(directory):\n            print(f'  - Rimozione: {directory}')\n            shutil.rmtree(directory)\n    print(\"‚úÖ Pulizia completata.\")\nelse:\n    print(\"‚è© CLEAN_RUN = False: I risultati precedenti vengono mantenuti.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:42:42.353740Z","iopub.execute_input":"2026-01-25T19:42:42.354492Z","iopub.status.idle":"2026-01-25T19:42:42.361431Z","shell.execute_reply.started":"2026-01-25T19:42:42.354447Z","shell.execute_reply":"2026-01-25T19:42:42.359871Z"}},"outputs":[{"name":"stdout","text":"üßπ CLEAN_RUN = True: Pulizia cartelle di output...\n‚úÖ Pulizia completata.\n","output_type":"stream"}],"execution_count":3},{"id":"aea9ffb0-c93f-40da-acea-1e7fd361d4a9","cell_type":"code","source":"# ==========================================\n# 4. IMPORT DATASET (COPY STRATEGY)\n# ==========================================\n\nRAW_DIR = \"data/raw\"\nos.makedirs(RAW_DIR, exist_ok=True)\n\nprint(f\"üì¶ Controllo Dataset in {RAW_DIR}...\")\n\nif KAGGLE_ENV:\n    if not os.path.exists(KAGGLE_INPUT_PATH):\n        print(f\"‚ö†Ô∏è ERRORE: Path {KAGGLE_INPUT_PATH} non trovato!\")\n    else:\n        copied_count = 0\n        # Cerca CSV ricorsivamente\n        for root, dirs, files in os.walk(KAGGLE_INPUT_PATH):\n            for file in files:\n                if file.lower().endswith(\".csv\"):\n                    src_path = os.path.join(root, file)\n                    dst_path = os.path.join(RAW_DIR, file)\n                    \n                    # Copia solo se non esiste\n                    if not os.path.exists(dst_path):\n                        print(f'  - Copia in corso: {file}...')\n                        shutil.copy2(src_path, dst_path)\n                        copied_count += 1\n        \n        if copied_count > 0:\n            print(f\"‚úÖ Copiati {copied_count} file nuovi.\")\n        else:\n            print(\"‚úÖ Tutti i file sono gi√† presenti in data/raw.\")\n            \n    # DEBUG: Stampa contenuto data/raw\n    print(f\"\\nüìÇ Contenuto attuale di {RAW_DIR}:\")\n    print(os.listdir(RAW_DIR))\nelse:\n    print(\"üíª Ambiente Locale: Verifica manuale richiesta per data/raw.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:42:42.363073Z","iopub.execute_input":"2026-01-25T19:42:42.363615Z","iopub.status.idle":"2026-01-25T19:42:54.169578Z","shell.execute_reply.started":"2026-01-25T19:42:42.363545Z","shell.execute_reply":"2026-01-25T19:42:54.168628Z"}},"outputs":[{"name":"stdout","text":"üì¶ Controllo Dataset in data/raw...\n  - Copia in corso: Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv...\n  - Copia in corso: Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv...\n  - Copia in corso: Tuesday-WorkingHours.pcap_ISCX.csv...\n  - Copia in corso: Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv...\n  - Copia in corso: Monday-WorkingHours.pcap_ISCX.csv...\n  - Copia in corso: Friday-WorkingHours-Morning.pcap_ISCX.csv...\n  - Copia in corso: Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv...\n  - Copia in corso: Wednesday-workingHours.pcap_ISCX.csv...\n‚úÖ Copiati 8 file nuovi.\n\nüìÇ Contenuto attuale di data/raw:\n['Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', 'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', 'Tuesday-WorkingHours.pcap_ISCX.csv', 'Monday-WorkingHours.pcap_ISCX.csv', 'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', 'Friday-WorkingHours-Morning.pcap_ISCX.csv', 'Wednesday-workingHours.pcap_ISCX.csv', 'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv']\n","output_type":"stream"}],"execution_count":4},{"id":"bea9ce3b-fc98-44ba-917e-3077fd739e1c","cell_type":"code","source":"# ==========================================\n# 5. PREPROCESSING (STRICT)\n# ==========================================\n# Nessun parametro passato, usa i default definiti in src/utils.py\n\nprint(\"‚öôÔ∏è Avvio Preprocessing...\")\n!python src/preprocessing.py --n-jobs 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:42:54.171819Z","iopub.execute_input":"2026-01-25T19:42:54.172656Z","iopub.status.idle":"2026-01-25T19:44:32.047599Z","shell.execute_reply.started":"2026-01-25T19:42:54.172625Z","shell.execute_reply":"2026-01-25T19:44:32.045870Z"}},"outputs":[{"name":"stdout","text":"‚öôÔ∏è Avvio Preprocessing...\n\n============================================================\nPREPROCESSING CIC-IDS2017\n============================================================\n\nParametri:\n  Input:         /kaggle/working/data/raw\n  Output:        /kaggle/working/data/processed\n  Balance:       Si (ratio 2.0:1)\n  Chunk size:    Disabilitato\n  Split:         70/15/15\n  CPU cores:     4/4\n\n1. Caricamento CSV da /kaggle/working/data/raw...\n2026-01-25 19:42:55 | INFO     | Trovati 8 file CSV\nCaricamento CSV: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:39<00:00,  4.97s/it]\n2026-01-25 19:43:35 | INFO     | Concatenazione 8 DataFrame...\n2026-01-25 19:43:36 | INFO     | Dataset combinato: 2,830,743 righe, 79 colonne\n2026-01-25 19:43:37 | INFO     | Memoria: 1.8 GB\n\n2. Pulizia dati...\n2026-01-25 19:43:37 | INFO     | Inizio pulizia dati...\n2026-01-25 19:43:37 | INFO     | Rimosse 1 colonne identificative\n2026-01-25 19:43:44 | INFO     | Rimosse 2,867 righe con valori infiniti\n2026-01-25 19:44:17 | INFO     | Rimosse 594,712 righe duplicate\n2026-01-25 19:44:18 | INFO     | Pulizia completata: 2,830,743 -> 2,233,164 righe\n\n3. Encoding label...\n2026-01-25 19:44:19 | INFO     | Encoding label...\n2026-01-25 19:44:20 | INFO     | Classi trovate: 15\n2026-01-25 19:44:20 | INFO     | Distribuzione binaria: Benign=1,896,672, Attack=336,492\n\n   Distribuzione classi:\n   - BENIGN: 1,896,672 (84.93%)\n   - DoS Hulk: 172,846 (7.74%)\n   - DDoS: 128,014 (5.73%)\n   - DoS GoldenEye: 10,286 (0.46%)\n   - FTP-Patator: 5,931 (0.27%)\n   - DoS slowloris: 5,385 (0.24%)\n   - DoS Slowhttptest: 5,228 (0.23%)\n   - SSH-Patator: 3,219 (0.14%)\n   - PortScan: 1,956 (0.09%)\n   - Web Attack ÔøΩ Brute Force: 1,470 (0.07%)\n   - Bot: 1,437 (0.06%)\n   - Web Attack ÔøΩ XSS: 652 (0.03%)\n   - Infiltration: 36 (0.00%)\n   - Web Attack ÔøΩ Sql Injection: 21 (0.00%)\n   - Heartbleed: 11 (0.00%)\n\n4. Bilanciamento (ratio 2.0:1)...\n2026-01-25 19:44:21 | INFO     | Bilanciamento dataset (ratio 2.0:1)...\n2026-01-25 19:44:22 | INFO     | Undersampling classe 0: 1,896,672 -> 672,984\n2026-01-25 19:44:24 | INFO     | Dataset bilanciato: 1,009,476 righe\n\n5. Split train/val/test...\n2026-01-25 19:44:24 | INFO     | Split dataset (70/15/15)...\n2026-01-25 19:44:26 | INFO     | Train: 706,632 | Val: 151,422 | Test: 151,422\n\n6. Salvataggio...\n2026-01-25 19:44:31 | INFO     | Dataset salvati in /kaggle/working/data/processed\n\n============================================================\nPREPROCESSING COMPLETATO\n============================================================\n\nOutput: /kaggle/working/data/processed\nTrain:  706,632 righe\nVal:    151,422 righe\nTest:   151,422 righe\nTiming: /kaggle/working/logs/timing/preprocessing_20260125_194255.json\n\nProssimo step: python src/feature_engineering.py\n\n--------------------------------------------------\nTIMING SUMMARY - preprocessing\n--------------------------------------------------\nSession: 20260125_194255\nTotal time: 95.48s\n\nOperations:\n  caricamento_csv               :    41.22s ( 43.2%)\n  pulizia_dati                  :    42.67s ( 44.7%)\n  encoding_label                :     1.06s (  1.1%)\n  bilanciamento                 :     3.35s (  3.5%)\n  split_dataset                 :     2.63s (  2.8%)\n  salvataggio                   :     4.38s (  4.6%)\n\nMetrics:\n  train_rows: 706632\n  val_rows: 151422\n  test_rows: 151422\n--------------------------------------------------\n2026-01-25 19:44:31 | INFO     | CPU: 4.9% | RAM: 13.6% | Disponibile: 27.1GB | Core attivi: 4/4\n","output_type":"stream"}],"execution_count":5},{"id":"96e6cbea-f7e6-4e2c-b922-4b51fe8a15e4","cell_type":"code","source":"# ==========================================\n# 6. FEATURE ENGINEERING (STRICT)\n# ==========================================\n# Nessun parametro passato\n\nprint(\"üß† Avvio Feature Engineering...\")\n!python src/feature_engineering.py --n-jobs 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:44:32.050282Z","iopub.execute_input":"2026-01-25T19:44:32.050997Z","iopub.status.idle":"2026-01-25T19:46:58.565778Z","shell.execute_reply.started":"2026-01-25T19:44:32.050954Z","shell.execute_reply":"2026-01-25T19:46:58.564226Z"}},"outputs":[{"name":"stdout","text":"üß† Avvio Feature Engineering...\n\n============================================================\nFEATURE ENGINEERING\n============================================================\n\nParametri:\n  Feature da selezionare: 30\n  RF estimators:          100\n  CPU cores:              4/4\n  Max RAM:                85%\n\n1. Caricamento dati preprocessati...\n2026-01-25 19:44:35 | INFO     | Caricati: train=706,632, val=151,422, test=151,422\n   Train: 706,632 | Val: 151,422 | Test: 151,422\n2026-01-25 19:44:35 | INFO     | CPU: 4.9% | RAM: 7.7% | Disponibile: 28.9GB | Core attivi: 4/4\n\n2. Esecuzione pipeline feature engineering...\n2026-01-25 19:44:35 | INFO     | Feature iniziali: 77\n2026-01-25 19:44:35 | INFO     | Fitting scaler su 706,632 campioni, 77 feature\n2026-01-25 19:44:37 | INFO     | Training RF per selezione feature (n_estimators=100, n_jobs=4)...\n   Training RF: 100 alberi su 706,632 campioni...\n   Core CPU in uso: 4\n   Questo puo richiedere 1-2 minuti...\n   RF training completato\n2026-01-25 19:46:55 | INFO     | Selezionate 30 feature su 77\n2026-01-25 19:46:56 | INFO     | Salvato: scaler.pkl\n2026-01-25 19:46:56 | INFO     | Salvato: selected_features.json\n2026-01-25 19:46:56 | INFO     | Salvato: scaler_columns.json (77 colonne)\n2026-01-25 19:46:56 | INFO     | Salvato: feature_importances.json\n2026-01-25 19:46:56 | INFO     | Feature engineering completato\n\n3. Salvataggio dataset pronti per training...\n   Salvati in /kaggle/working/data/processed\n\n   Top 10 feature selezionate:\n2026-01-25 19:46:57 | INFO     | Caricati artifacts da /kaggle/working/artifacts\n    1. Bwd Packet Length Std: 0.1077\n    2. Bwd Packet Length Max: 0.0759\n    3. Packet Length Variance: 0.0613\n    4. Avg Bwd Segment Size: 0.0580\n    5. Bwd Packet Length Mean: 0.0573\n    6. Packet Length Std: 0.0470\n    7. Subflow Bwd Bytes: 0.0454\n    8. Packet Length Mean: 0.0352\n    9. Average Packet Size: 0.0349\n   10. Total Fwd Packets: 0.0274\n\n============================================================\nFEATURE ENGINEERING COMPLETATO\n============================================================\n\nArtifacts: /kaggle/working/artifacts\nShape:     (706,632, 30)\nTiming:    /kaggle/working/logs/timing/feature_engineering_20260125_194434.json\n\nProssimo step: python src/training/random_forest.py\n\n--------------------------------------------------\nTIMING SUMMARY - feature_engineering\n--------------------------------------------------\nSession: 20260125_194434\nTotal time: 143.67s\n\nOperations:\n  caricamento_dati              :     1.04s (  0.7%)\n  feature_engineering_pipeline  :   140.64s ( 97.9%)\n  salvataggio_dataset           :     1.88s (  1.3%)\n\nMetrics:\n  train_samples: 706632\n  n_features_selected: 30\n--------------------------------------------------\n2026-01-25 19:46:58 | INFO     | CPU: 2.5% | RAM: 8.6% | Disponibile: 28.7GB | Core attivi: 4/4\n","output_type":"stream"}],"execution_count":6},{"id":"12d78cb1-a478-4aec-aa8a-ec6d3cc39c98","cell_type":"code","source":"###### ==========================================\n# 7. HYPERPARAMETER TUNING (STRICT)\n# ==========================================\n\ncmd = [\n    'python', 'src/hyperparameter_tuning.py',\n    '--model', MODEL_TYPE\n]\n\nif N_TRIALS is not None:\n    cmd += ['--n-trials', str(N_TRIALS)]\n\nif TIMEOUT is not None:\n    cmd += ['--timeout', str(TIMEOUT)]\n\ncmd_str = \" \".join(cmd)\nprint(f\"üöÄ Avvio Tuning: {cmd_str}\")\n\n!{cmd_str}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:46:58.567790Z","iopub.execute_input":"2026-01-25T19:46:58.568394Z","iopub.status.idle":"2026-01-25T19:48:14.499058Z","shell.execute_reply.started":"2026-01-25T19:46:58.568352Z","shell.execute_reply":"2026-01-25T19:48:14.497457Z"}},"outputs":[{"name":"stdout","text":"üöÄ Avvio Tuning: python src/hyperparameter_tuning.py --model lightgbm --n-trials 60 --timeout 60\n\n======================================================================\nHYPERPARAMETER TUNING\n======================================================================\n\nModello:      lightgbm\nMetodo:       Bayesian Optimization (Optuna)\nMetrica:      70% F2-Score + 30% Latency (composite)\nTask:         binary\nCV:           5\nMax Latency:  1.0ms/sample\nCPU:          2/4\nLimiti:       60 trials OPPURE 60s (0.0h)\n              (si ferma al primo raggiunto)\n\n1. Caricamento dati...\n2026-01-25 19:47:09 | INFO     | Caricati: train=706,632, val=151,422, test=151,422\n2. Preparazione feature...\n2026-01-25 19:47:09 | INFO     | Caricati artifacts da /kaggle/working/artifacts\n   Shape: (706632, 30)\n\n3. Tuning (Bayesian Optuna)...\n   NOTA: Misura latency durante CV, rallenta il processo\n2026-01-25 19:47:10 | INFO     | Bayesian Optimization (Optuna): cv=5\n2026-01-25 19:47:10 | INFO     | Metrica: 70% F2-Score + 30% Latency\n2026-01-25 19:47:10 | INFO     | Max latency constraint: 1.0ms/sample\n2026-01-25 19:47:10 | INFO     | Limiti: 60 trials OPPURE 60s (0.0h) - si ferma al primo\nBest trial: 0. Best value: 0.997844:  10%| | 6/60 [01:00<09:03, 10.06s/it, 60.36\n2026-01-25 19:48:13 | INFO     | Best composite score: 0.9978\n2026-01-25 19:48:13 | INFO     |   - F2-Score: 0.9973\n2026-01-25 19:48:13 | INFO     |   - Latency: 0.0003ms/sample\n2026-01-25 19:48:13 | INFO     | Completed trials: 6\n2026-01-25 19:48:13 | INFO     | Best params: {'n_estimators': 4, 'max_depth': 29, 'learning_rate': 0.06504856968981275, 'num_leaves': 188, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'min_child_samples': 15, 'reg_alpha': 0.6245760287469893, 'reg_lambda': 0.002570603566117598, 'class_weight': 'balanced'}\n\n4. Salvataggio risultati...\n\n======================================================================\nTUNING COMPLETATO\n======================================================================\n\nBest composite score: 0.9978\n  - F2-Score: 0.9973\n  - Latency:  0.0003ms/sample\n\nTrials completati: 6\nTempo totale: 60.4s (0.02h)\n\nBest params:\n  n_estimators: 4\n  max_depth: 29\n  learning_rate: 0.06504856968981275\n  num_leaves: 188\n  subsample: 0.5780093202212182\n  colsample_bytree: 0.5779972601681014\n  min_child_samples: 15\n  reg_alpha: 0.6245760287469893\n  reg_lambda: 0.002570603566117598\n  class_weight: balanced\n\nRisultati salvati: /kaggle/working/tuning_results/lightgbm/bayesian_trials6_cv5_2026-01-25_19.48.json\n\nProssimo step:\n  python src/training/lightgbm.py\n","output_type":"stream"}],"execution_count":7},{"id":"85937746-36b3-47cc-9f35-1b2ea0a692c0","cell_type":"code","source":"# ==========================================\n# 8. SALVATAGGIO OUTPUT\n# ==========================================\n\nOUTPUT_ZIP = \"tuning_results_pack.zip\"\nDIRS_TO_SAVE = [\"tuning_results\", \"artifacts\"] # Aggiungi 'models' se necessario\n\nprint(\"üì¶ Creazione archivio finale...\")\n\nexisting_dirs = [d for d in DIRS_TO_SAVE if os.path.exists(d)]\n\nif existing_dirs:\n    dirs_str = \" \".join(existing_dirs)\n    !zip -qr {OUTPUT_ZIP} {dirs_str}\n    print(f\"‚úÖ Archivio pronto: {OUTPUT_ZIP} (Scarica File)\")\n    \n    # Lista contenuto zip per verifica\n    # !unzip -l {OUTPUT_ZIP}\nelse:\n    print(\"‚ö†Ô∏è Nessun risultato trovato da salvare.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T19:48:14.501078Z","iopub.execute_input":"2026-01-25T19:48:14.501631Z","iopub.status.idle":"2026-01-25T19:48:14.634524Z","shell.execute_reply.started":"2026-01-25T19:48:14.501589Z","shell.execute_reply":"2026-01-25T19:48:14.633426Z"}},"outputs":[{"name":"stdout","text":"üì¶ Creazione archivio finale...\n‚úÖ Archivio pronto: tuning_results_pack.zip (Scarica File)\n","output_type":"stream"}],"execution_count":8}]}