{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.10.0","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NIDS-ML: Network Intrusion Detection System\n\nPipeline completa: preprocessing, feature engineering, training, evaluation e test su PCAP.\n\n**Requisiti Kaggle**:\n- Dataset CIC-IDS2017 (CSV)\n- Dataset `cicids2017-test-pcap` (opzionale, per test PCAP)","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup Ambiente","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nfrom pathlib import Path\n\nif Path(\"/kaggle/input\").exists():\n    ENV = \"kaggle\"\n    PROJECT_ROOT = Path(\"/kaggle/working\")\n    DATA_INPUT = Path(\"/kaggle/input\")\nelif Path(\"/content\").exists():\n    ENV = \"colab\"\n    PROJECT_ROOT = Path(\"/content/NIDS-ML\")\n    DATA_INPUT = Path(\"/content\")\nelse:\n    ENV = \"local\"\n    PROJECT_ROOT = Path.cwd()\n    if not (PROJECT_ROOT / \"src\").exists():\n        PROJECT_ROOT = PROJECT_ROOT.parent\n    DATA_INPUT = PROJECT_ROOT / \"data\" / \"raw\"\n\nprint(f\"Ambiente: {ENV}\")\nprint(f\"Project root: {PROJECT_ROOT}\")\nprint(f\"Data input: {DATA_INPUT}\")\n\nsys.path.insert(0, str(PROJECT_ROOT))\nos.chdir(PROJECT_ROOT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"REPO_URL = \"https://github.com/Riiccardob/NIDS-ML-SSR2\"\n\nif ENV in [\"kaggle\", \"colab\"]:\n    if not (PROJECT_ROOT / \"src\").exists():\n        print(f\"Cloning project from {REPO_URL}...\")\n        !git clone {REPO_URL} temp_repo\n        !cp -r temp_repo/* {PROJECT_ROOT}/\n        !rm -rf temp_repo\n        print(\"Project cloned.\")\n        if (PROJECT_ROOT / \"requirements.txt\").exists():\n            !pip install -q -r {PROJECT_ROOT}/requirements.txt\n    else:\n        print(\"Project already loaded.\")\n\nif (PROJECT_ROOT / \"src\").exists():\n    print(f\"\\nModuli disponibili:\")\n    for f in sorted((PROJECT_ROOT / \"src\").glob(\"*.py\")):\n        print(f\"  - {f.name}\")\nelse:\n    raise FileNotFoundError(\"Cartella src/ non trovata!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for d in [\"data/raw\", \"data/processed\", \"artifacts\", \"models\", \"logs\", \"reports\"]:\n    (PROJECT_ROOT / d).mkdir(parents=True, exist_ok=True)\nprint(\"Directory create.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if ENV in [\"kaggle\", \"colab\"]:\n    dataset_patterns = [\"cicids2017\", \"cic-ids-2017\", \"cicids\", \"ids2017\", \"network-intrusion-dataset\"]\n    dataset_path = None\n    for p in DATA_INPUT.iterdir():\n        name_lower = p.name.lower()\n        if \"pcap\" in name_lower:\n            continue\n        if any(pat in name_lower for pat in dataset_patterns):\n            if list(p.glob(\"**/*.csv\")):\n                dataset_path = p\n                break\n    if dataset_path:\n        print(f\"Dataset CSV trovato: {dataset_path}\")\n        raw_dir = PROJECT_ROOT / \"data\" / \"raw\"\n        for csv in dataset_path.glob(\"**/*.csv\"):\n            dest = raw_dir / csv.name\n            if not dest.exists():\n                !cp \"{csv}\" \"{dest}\"\n        print(f\"CSV copiati in: {raw_dir}\")\n    else:\n        print(\"ERRORE: Dataset CIC-IDS2017 non trovato!\")\n\ncsv_files = list((PROJECT_ROOT / \"data\" / \"raw\").glob(\"*.csv\"))\nprint(f\"\\nCSV disponibili: {len(csv_files)}\")\nfor f in csv_files:\n    size_mb = f.stat().st_size / (1024**2)\n    print(f\"  - {f.name}: {size_mb:.1f} MB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Preprocessing","metadata":{}},{"cell_type":"code","source":"from src.preprocessing import main as preprocessing_main\nfrom src.preprocessing import load_processed_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nimport sys\nsys.argv = ['preprocessing.py', '--balance-ratio', '2.0', '--n-jobs', '4']\npreprocessing_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train, val, test, mappings = load_processed_data()\nprint(f\"Train: {len(train):,} | Val: {len(val):,} | Test: {len(test):,}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Feature Engineering","metadata":{}},{"cell_type":"code","source":"from src.feature_engineering import main as feature_engineering_main\nfrom src.feature_engineering import load_artifacts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['feature_engineering.py', '--n-features', '30', '--rf-estimators', '100', '--n-jobs', '4']\nfeature_engineering_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler, selected_features, importances, scaler_columns = load_artifacts()\nprint(f\"Feature selezionate: {len(selected_features)}\")\nprint(f\"Colonne scaler: {len(scaler_columns)}\")\nprint(f\"\\nTop 10 feature:\")\nfor i, feat in enumerate(selected_features[:10]):\n    print(f\"  {i+1:2}. {feat}: {importances[feat]:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Training Modelli (Definitivo)\n\nParametri: `--n-iter 50 --cv 5` (250 fit per modello)","metadata":{}},{"cell_type":"code","source":"from src.training.random_forest import main as rf_main\nfrom src.training.xgboost_model import main as xgb_main\nfrom src.training.lightgbm_model import main as lgbm_main","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# Random Forest\nsys.argv = ['random_forest.py', '--task', 'binary', '--n-iter', '50', '--cv', '5', '--n-jobs', '4']\nrf_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# XGBoost\nsys.argv = ['xgboost_model.py', '--task', 'binary', '--n-iter', '50', '--cv', '5', '--n-jobs', '4']\nxgb_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# LightGBM\nsys.argv = ['lightgbm_model.py', '--task', 'binary', '--n-iter', '50', '--cv', '5', '--n-jobs', '4']\nlgbm_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nprint(\"Modelli addestrati:\")\nfor model_dir in (PROJECT_ROOT / \"models\").iterdir():\n    if model_dir.is_dir() and model_dir.name != \"best_model\":\n        results_file = model_dir / \"results_binary.json\"\n        if results_file.exists():\n            with open(results_file) as f:\n                results = json.load(f)\n            metrics = results.get('validation_metrics', {})\n            print(f\"\\n  {model_dir.name}: Acc={metrics.get('accuracy', 0):.4f}, F1={metrics.get('f1', 0):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Evaluation","metadata":{}},{"cell_type":"code","source":"from src.evaluation import main as evaluation_main","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['evaluation.py', '--model-path', 'models/random_forest/model_binary.pkl']\nevaluation_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['evaluation.py', '--model-path', 'models/xgboost/model_binary.pkl']\nevaluation_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsys.argv = ['evaluation.py', '--model-path', 'models/lightgbm/model_binary.pkl']\nevaluation_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Confronto e Selezione Best Model","metadata":{}},{"cell_type":"code","source":"from src.compare_models import main as compare_main","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# max-fpr: False Positive Rate massimo accettabile (2%)\n# max-latency-ms: Latenza massima per predizione (1ms)\nsys.argv = ['compare_models.py', '--max-fpr', '0.02', '--max-latency-ms', '1.0']\ncompare_main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_dir = PROJECT_ROOT / \"models\" / \"best_model\"\nif best_model_dir.exists():\n    print(f\"Best model: {best_model_dir}\")\n    for f in best_model_dir.iterdir():\n        print(f\"  - {f.name}\")\n    metadata_file = best_model_dir / \"metadata.json\"\n    if metadata_file.exists():\n        with open(metadata_file) as f:\n            print(f\"\\nBest: {json.load(f).get('best_model', 'N/A')}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Visualizzazioni","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom IPython.display import Image, display\n\nscorecard_img = PROJECT_ROOT / \"models\" / \"best_model\" / \"scorecard_comparison.png\"\nif scorecard_img.exists():\n    print(\"Scorecard:\")\n    display(Image(filename=str(scorecard_img)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_name = \"lightgbm\"\nmetadata_file = PROJECT_ROOT / \"models\" / \"best_model\" / \"metadata.json\"\nif metadata_file.exists():\n    with open(metadata_file) as f:\n        best_model_name = json.load(f).get('best_model', 'lightgbm')\n\nreport_dir = PROJECT_ROOT / \"reports\" / best_model_name\nif report_dir.exists():\n    for img_name in [\"confusion_matrix_binary.png\", \"roc_curve_binary.png\"]:\n        img_path = report_dir / img_name\n        if img_path.exists():\n            print(f\"\\n{img_name}:\")\n            display(Image(filename=str(img_path)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## 8. Test Sniffer su PCAP\n\nUsa la funzione `analyze_pcap_file()` da `src/sniffer.py`.\n\nDataset: `cicids2017-test-pcap` con `test_pcap/*.pcap`","metadata":{}},{"cell_type":"code","source":"# Cerca dataset PCAP\npcap_patterns = [\"pcap\", \"test-pcap\", \"test_pcap\"]\npcap_dataset_path = None\npcap_files = []\n\nif ENV in [\"kaggle\", \"colab\"]:\n    for p in DATA_INPUT.iterdir():\n        if any(pat in p.name.lower() for pat in pcap_patterns):\n            found = list(p.glob(\"**/*.pcap\")) + list(p.glob(\"**/*.pcapng\"))\n            if found:\n                pcap_dataset_path = p\n                pcap_files = found\n                break\n\nif pcap_files:\n    print(f\"Dataset PCAP: {pcap_dataset_path}\")\n    for f in pcap_files:\n        print(f\"  - {f.name}: {f.stat().st_size/(1024**2):.1f} MB\")\nelse:\n    print(\"Dataset PCAP non trovato (opzionale).\")\n    print(\"Per testare, aggiungi dataset 'cicids2017-test-pcap' al notebook.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import funzione analyze_pcap_file da sniffer.py\nif pcap_files:\n    from src.sniffer import analyze_pcap_file\n    print(\"Funzione analyze_pcap_file importata da src/sniffer.py\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# Analizza tutti i PCAP usando la funzione del progetto\nall_pcap_results = []\n\nif pcap_files:\n    for pcap_path in pcap_files:\n        print(f\"\\n\\n{'#'*70}\")\n        print(f\"# PCAP: {pcap_path.name}\")\n        print(f\"{'#'*70}\")\n        \n        # Usa la funzione analyze_pcap_file da sniffer.py\n        result = analyze_pcap_file(\n            pcap_path=str(pcap_path),\n            model_path=None,  # Usa best_model di default\n            threshold=0.5,    # Soglia standard\n            timeout=60,       # Timeout flusso 60s\n            min_packets=2,    # Minimo 2 pacchetti\n            verbose=False,    # Non stampare ogni flusso\n            progress_interval=50000  # Progress ogni 50k pacchetti\n        )\n        all_pcap_results.append(result)\nelse:\n    print(\"Nessun PCAP da analizzare.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Riepilogo finale PCAP\nif all_pcap_results:\n    print(\"\\n\" + \"=\"*70)\n    print(\"RIEPILOGO TEST PCAP\")\n    print(\"=\"*70)\n    \n    tot_pkt = sum(r['packets_processed'] for r in all_pcap_results)\n    tot_fl = sum(r['flows_analyzed'] for r in all_pcap_results)\n    tot_att = sum(r['attacks_detected'] for r in all_pcap_results)\n    tot_ben = sum(r['benign_detected'] for r in all_pcap_results)\n    \n    print(f\"\\nTotale:\")\n    print(f\"  Pacchetti:  {tot_pkt:,}\")\n    print(f\"  Flussi:     {tot_fl:,}\")\n    print(f\"  Attacchi:   {tot_att:,} ({tot_att/tot_fl*100:.1f}%)\" if tot_fl > 0 else \"\")\n    print(f\"  Benigni:    {tot_ben:,}\")\n    \n    print(f\"\\n{'PCAP':<35} {'Packets':>12} {'Flows':>10} {'Attacks':>10} {'Rate':>8}\")\n    print(\"-\"*77)\n    for r in all_pcap_results:\n        pct = r.get('detection_rate', 0)\n        print(f\"{r['pcap']:<35} {r['packets_processed']:>12,} {r['flows_analyzed']:>10,} {r['attacks_detected']:>10,} {pct:>7.1f}%\")\n    \n    # Salva risultati\n    results_path = PROJECT_ROOT / \"reports\" / \"pcap_test_results.json\"\n    with open(results_path, 'w') as f:\n        json.dump(all_pcap_results, f, indent=2, default=str)\n    print(f\"\\nRisultati salvati: {results_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizzazione distribuzione probabilita\nif all_pcap_results:\n    import matplotlib.pyplot as plt\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Grafico 1: Attacchi vs Benigni per PCAP\n    pcap_names = [r['pcap'][:25] for r in all_pcap_results]\n    attacks = [r['attacks_detected'] for r in all_pcap_results]\n    benign = [r['benign_detected'] for r in all_pcap_results]\n    \n    x = range(len(pcap_names))\n    width = 0.35\n    axes[0].bar([i-width/2 for i in x], attacks, width, label='Attacks', color='red', alpha=0.7)\n    axes[0].bar([i+width/2 for i in x], benign, width, label='Benign', color='green', alpha=0.7)\n    axes[0].set_xticks(x)\n    axes[0].set_xticklabels(pcap_names, rotation=45, ha='right')\n    axes[0].set_ylabel('Flussi')\n    axes[0].set_title('Distribuzione Rilevamenti')\n    axes[0].legend()\n    \n    # Grafico 2: Detection Rate\n    rates = [r.get('detection_rate', 0) for r in all_pcap_results]\n    colors = ['red' if r > 30 else 'orange' if r > 10 else 'green' for r in rates]\n    axes[1].bar(x, rates, color=colors, alpha=0.7)\n    axes[1].set_xticks(x)\n    axes[1].set_xticklabels(pcap_names, rotation=45, ha='right')\n    axes[1].set_ylabel('Detection Rate (%)')\n    axes[1].set_title('Percentuale Attacchi Rilevati')\n    axes[1].axhline(y=20, color='orange', linestyle='--', alpha=0.5, label='20% atteso')\n    axes[1].legend()\n    \n    plt.tight_layout()\n    plt.savefig(PROJECT_ROOT / \"reports\" / \"pcap_test_chart.png\", dpi=150)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Download Output","metadata":{}},{"cell_type":"code","source":"if ENV in [\"kaggle\", \"colab\"]:\n    import zipfile\n    zip_path = PROJECT_ROOT / \"nids_ml_output.zip\"\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n        for f in (PROJECT_ROOT/\"artifacts\").glob(\"*\"): z.write(f, f\"artifacts/{f.name}\")\n        for d in (PROJECT_ROOT/\"models\").iterdir():\n            if d.is_dir():\n                for f in d.glob(\"*\"): z.write(f, f\"models/{d.name}/{f.name}\")\n        for f in (PROJECT_ROOT/\"reports\").rglob(\"*\"):\n            if f.is_file(): z.write(f, f\"reports/{f.relative_to(PROJECT_ROOT/'reports')}\")\n    print(f\"ZIP: {zip_path} ({zip_path.stat().st_size/(1024**2):.1f} MB)\")\nelse:\n    print(\"Locale - output in cartella progetto.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10. Riepilogo","metadata":{}},{"cell_type":"code","source":"print(\"=\"*70)\nprint(\"PIPELINE COMPLETATA\")\nprint(\"=\"*70)\n\nbest_report = PROJECT_ROOT / \"models\" / \"best_model\" / \"comparison_results.json\"\nif best_report.exists():\n    with open(best_report) as f:\n        results = json.load(f)\n    best = max(results, key=lambda x: x.get('score', 0))\n    print(f\"\\nBest Model: {best['model_name'].upper()}\")\n    for k, v in best.get('metrics', {}).items():\n        if isinstance(v, float):\n            print(f\"  {k}: {v:.4f}\")\n\nif all_pcap_results:\n    tot_fl = sum(r['flows_analyzed'] for r in all_pcap_results)\n    tot_att = sum(r['attacks_detected'] for r in all_pcap_results)\n    print(f\"\\nTest PCAP: {tot_fl:,} flussi, {tot_att:,} attacchi ({tot_att/tot_fl*100:.1f}%)\" if tot_fl > 0 else \"\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Comandi per uso locale:\")\nprint(\"  # Live capture\")\nprint(\"  sudo python src/sniffer.py --interface eth0 --verbose\")\nprint(\"\")\nprint(\"  # Analisi PCAP\")\nprint(\"  sudo python src/sniffer.py --pcap file.pcap --threshold 0.3 --min-packets 1\")\nprint(\"\")\nprint(\"  # Da Python/notebook\")\nprint(\"  from src.sniffer import analyze_pcap_file\")\nprint(\"  results = analyze_pcap_file('file.pcap', threshold=0.3)\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
